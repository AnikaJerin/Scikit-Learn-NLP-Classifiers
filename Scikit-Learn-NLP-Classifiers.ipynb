{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load_file And Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!',\n",
       " 4.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file_name='./data/sentiment/Books_small.json'\n",
    "reviews=[]\n",
    "with open(file_name) as  f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "#         print(review['reviewText'])\n",
    "#         print(review['overall'])\n",
    "#         break #cz right now you don't have to read all reviews; just reading one review and breaking the loop\n",
    "        reviews.append((review['reviewText'],review['overall']))\n",
    "reviews[5] #taking reviews with score\n",
    "# reviews[5][0] #taking only review \n",
    "# reviews[5][1] #taking only scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing Same thing Using Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text=text\n",
    "        self.Score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.Score <= 2:\n",
    "            return \"NEGATIVE\"\n",
    "        elif self.Score == 3:\n",
    "            return \"NUTRAL\"\n",
    "        else:\n",
    "            return \"POSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file_name='./data/sentiment/Books_small.json'\n",
    "reviews=[]\n",
    "with open(file_name) as  f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall'])) #creating objects for Review class\n",
    "# reviews[5].text\n",
    "reviews[5].sentiment\n",
    "reviews[5].text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Texts into Quantitive Vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of words : if we have two lines such as \"this book was so good\" and \"this book was very bad\". First we have to break this into a\n",
    "#### dicionary of tokens; may be a unigram like a single word as a dictionary. here--> this, book, was, so, good,very , bad\n",
    "#### to convert this into vector all we have to do is map ones and zeroses to the terms over here \n",
    "#### so, this book was so good would have ones mapped to the 1st 5 words but last 2 words would have zero mapped into it  cz it has negative vibe. \n",
    "#### For the 1st line it would be 1,1,1,1,1,0,0\n",
    "#### For the 2nd line it would be 1,1,1,0,0,1,1 (see the ss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''If you do not use a random_state in train_test_split, every time you make the split you might get a different set of train and test data points '''\n",
    "training, test=train_test_split(reviews, test_size=0.33, random_state=42) # 33% of the total data are gonna be in the training set\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "## passing the training_set into bag of words vectorizer\n",
    "print(training[4].sentiment)\n",
    "print(training[4].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=[x.text for x in training] # storing the text part of the \n",
    "train_y=[x.sentiment for x in training] # storing the sentiment part of the either pos or neg\n",
    "\n",
    "test_x=[x.text for x in test] # storing the text part of the \n",
    "test_y=[x.sentiment for x in test]\n",
    "train_x[0]\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# This book was so good !\n",
    "# This book was very bad\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "print(train_x[0])\n",
    "# print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7086)\t1\n",
      "  (0, 1148)\t1\n",
      "  (0, 350)\t2\n",
      "  (0, 1800)\t1\n",
      "  (0, 6595)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 3054)\t1\n",
      "  (0, 1558)\t1\n",
      "  (0, 6475)\t1\n",
      "  (0, 6593)\t1\n",
      "  (0, 2895)\t1\n",
      "  (0, 7353)\t1\n",
      "  (0, 539)\t1\n",
      "  (0, 1515)\t1\n",
      "  (0, 5197)\t1\n",
      "  (0, 3545)\t1\n",
      "  (0, 2007)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x_vectors[0].toarrayay())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
